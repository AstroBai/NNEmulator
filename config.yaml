DataParam:
  Training_ParamPath: /path/to/train_params.npy # N_train x N_params array
  Training_DataPath: /path/to/train_data.npy # N_train x N_outputs array
  Trial_ParamPath: /path/to/trial_params.npy # N_trial x N_params array
  Trial_DataPath: /path/trial_data.npy # N_trial x N_outputs array
  xs_Path: /path/to/x-axis.npy # N_outputs array
  Do_Log: False # Whether to take the logarithm of the data

ANNParam:
  Device: 'cpu' # 'cuda' or 'cpu'
  Scale_Params: True # Whether to scale input parameters to [0, 1]
  Use_PCA: True # Whether to use PCA for dimensionality reduction
  N_PCA_Components: 16 # Number of PCA components to retain if Use_PCA is
  S_Hidden: [24, 20] # Number of nodes in each hidden layer
  Activation: 'silu' # Activation function: 'tanh', 'relu', 'sigmoid', 'linear', 'gelu', 'silu (current best)'
  Positive_Output: False # Whether to enforce positive output using softplus
  Step_LR: True # Whether to use step learning rate
  Initial_LR: 0.01 # Initial learning rate
  Step_Size: 100 # Step size for learning rate decay
  Gamma: 0.1 # Learning rate decay factor
  Max_Epochs: 100000 # Maximum number of epochs
  Early_Stopping: True # Whether to use early stopping
  Patience: 10 # Patience for early stopping
  Min_Delta: 1e-6 # Minimum change to qualify as an improvement
  Dropout: 0 # Dropout rate (0.0 means no dropout)
  Weight_Decay: 0 # Weight decay (L2 regularization)
  Plot_Loss: True # Whether to plot the loss curve

OutputParam:
  Model_SavePath: /directory/to/your/model # Path to save trained models, you can also see the loss curve here if Plot_Loss is True